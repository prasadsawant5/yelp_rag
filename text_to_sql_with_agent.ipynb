{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will work on converting text to SQL queries that can be run on Yelp dataset using an SQL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/chromadb/\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for jq (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  Executing: ./configure CFLAGS=-fPIC --prefix=C:\\Users\\sawant_pra\\AppData\\Local\\Temp\\pip-install-92sxaxhm\\jq_275f238697924df283a3bb7d61d0237b\\_deps\\build\\onig-install-6.9.8\n",
      "  error: [WinError 2] The system cannot find the file specified\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for jq\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hnswlib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'hnswlib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hnswlib\n",
      "ERROR: Could not build wheels for jq, hnswlib, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "%pip --quiet install langchain tqdm psycopg2 google-cloud-aiplatform==1.38.0 jq faiss-gpu transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql_database\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLDatabase\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_sql_agent\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DATABASE_NAME, USERNAME, PASSWORD\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "from .config import DATABASE_NAME, USERNAME, PASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USERNAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m HOST \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m PORT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5432\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m pg_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql+psycopg2://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mUSERNAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPASSWORD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATABASE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'USERNAME' is not defined"
     ]
    }
   ],
   "source": [
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "pg_uri = f\"postgresql+psycopg2://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE_NAME}\"\n",
    "\n",
    "db = SQLDatabase.from_uri(pg_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_KEY_PATH = 'llm-study-413709-40a30207144b.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = SERVICE_ACCOUNT_KEY_PATH\n",
    "\n",
    "PROJECT = 'llm-study-413709'\n",
    "LOCATION = 'us-central1'\n",
    "MODEL_NAME = 'codechat-bison'\n",
    "\n",
    "llm = ChatVertexAI(project=PROJECT, \n",
    "                   location=LOCATION, \n",
    "                   model_name=MODEL_NAME,\n",
    "                   temperature=0.0, \n",
    "                   max_output_tokens=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom embeddings class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVertexAIEmbeddings(VertexAIEmbeddings, Embeddings):\n",
    "    model_name = 'textembedding-gecko'\n",
    "    max_batch_size = 5\n",
    "    \n",
    "    def embed_segments(self, segments: List) -> List:\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(segments), self.max_batch_size)):\n",
    "            batch = segments[i: i+self.max_batch_size]\n",
    "            embeddings.extend(self.client.get_embeddings(batch))\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    \n",
    "    def embed_query(self, query: str) -> List:\n",
    "        embeddings = self.client.get_embeddings([query])\n",
    "        return embeddings[0].values\n",
    "    \n",
    "embeddings = MyVertexAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare schema documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_document = JSONLoader(file_path='./schemas/tables.jsonl', jq_schema='.', text_content=False, json_lines=True).load()\n",
    "columns_document = JSONLoader(file_path='./schemas/columns.jsonl', jq_schema='.', text_content=False, json_lines=True).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper method for retrieving matched tables from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_tables(query: str) -> List:\n",
    "    db = FAISS.from_documents(documents=tables_document, embedding=embeddings)\n",
    "    retriever = db.as_retriever(search_type='mmr', search_kwargs={'k': 5, 'lambda_mult': 1})\n",
    "    matched_documents = retriever.get_relevant_documents(query=query)\n",
    "\n",
    "    return matched_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper method for retrieving matched columns from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_columns(query: str) -> List:\n",
    "    db = FAISS.from_documents(documents=columns_document, embedding=embeddings)\n",
    "    search_kwargs = {\n",
    "        'k': 20\n",
    "    }\n",
    "\n",
    "    retriever = db.as_retriever(search_type='similarity', search_kwargs=search_kwargs)\n",
    "    matched_columns = retriever.get_relevant_documents(query=query)\n",
    "\n",
    "    return matched_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "template = \"You are a SQL master expert capable of writing complex SQL query in Postgres.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "messages.append(system_message_prompt)\n",
    "\n",
    "human_template = \"\"\"Given the following inputs:\n",
    "USER_QUERY:\n",
    "--\n",
    "{query}\n",
    "--\n",
    "MATCHED_SCHEMA: \n",
    "--\n",
    "{matched_schema}\n",
    "--\n",
    "Please construct a SQL query using the MATCHED_SCHEMA and the USER_QUERY provided above. \n",
    "\n",
    "IMPORTANT: Use ONLY the column names (column_name) mentioned in MATCHED_SCHEMA. DO NOT USE any other column names outside of this. \n",
    "IMPORTANT: Associate column_name mentioned in MATCHED_SCHEMA only to the table_name specified under MATCHED_SCHEMA.\n",
    "NOTE: Use SQL 'AS' statement to assign a new name temporarily to a table column or even a table wherever needed. \n",
    "\"\"\"\n",
    "human_message = HumanMessagePromptTemplate.from_template(human_template)\n",
    "messages.append(human_message)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "user_question = 'Which user from Boston checked in into a SPA and then went to an Italian restaurant?'\n",
    "matched_columns = get_matched_columns(user_question)\n",
    "\n",
    "request = chat_prompt.format_prompt(query=user_question,\n",
    "    matched_schema=matched_columns).to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(llm=llm, \n",
    "                                  toolkit=toolkit,  \n",
    "                                  top_k=10, \n",
    "                                  prompt=request, \n",
    "                                  return_intermediate_steps=True, \n",
    "                                  verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
